{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix7BXMwAIChK",
        "outputId": "dfed6356-6fb4-484d-c930-2efe9d960427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl00EiDHIOEG"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Infosys/css-data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XaDjNfLIPUj",
        "outputId": "9e2f86f4-d8be-4306-d87c-d1b8bfa3c14e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "css-data/\n",
            "  README.dataset.txt\n",
            "  README.roboflow.txt\n",
            "  css-data.yaml\n",
            "  valid/\n",
            "    images/\n",
            "      -1969-_png_jpg.rf.41dd58ed3ae83df95fb2417c679d581f.jpg\n",
            "      -1079-_png_jpg.rf.19092a3937930012f9fd9c1ce57f5a7b.jpg\n",
            "      -1429-_png_jpg.rf.78a7894e86c79d018d80fa86f4d000f8.jpg\n",
            "      construction-2-_mp4-38_jpg.rf.0bb63aba0a9ebe5a4741a6207e2e1902.jpg\n",
            "      autox3_mp4-78_jpg.rf.dc5c00104c4cf733c2c06c820b82d338.jpg\n",
            "    labels/\n",
            "      construction-4-_mp4-20_jpg.rf.cb627b855fa08d83357febb83f6ad4bc.txt\n",
            "      004424_jpg.rf.0470713b945b08839105cde711db62d9.txt\n",
            "      02646_jpg.rf.5c93ba95bdc03808bcf872c7218ac5ef.txt\n",
            "      IMG_3100_mp4-1_jpg.rf.7b4a6df995ec2702dee6e7f8c5b47e14.txt\n",
            "      IMG_3093_mp4-22_jpg.rf.ea118a6046b21e9246efd53599dfdc41.txt\n",
            "  train/\n",
            "    labels/\n",
            "      image_170_jpg.rf.2be45261d9b8c9e3ad48f1d5992a81e0.txt\n",
            "      image_246_jpg.rf.5b09f63561fa416c6e982b459acf98d4.txt\n",
            "      image_426_jpg.rf.c89dce1cff780e9d86a5bf5f3b16459c.txt\n",
            "      image_28_jpg.rf.83228814ea921754456d144a3d128bf4.txt\n",
            "      image_418_jpg.rf.e566fa0d44b45d557b0b035a7d8d9e4e.txt\n",
            "    images/\n",
            "      image_46_jpg.rf.fca0eb9eb04c5c3fc20e3783f18f56f2.jpg\n",
            "      image_678_jpg.rf.d08dc280ff6c031f30f59a759080ddf7.jpg\n",
            "      image_740_jpg.rf.1cba9cb31d4c4bdae3a275b9491589b8.jpg\n",
            "      image_704_jpg.rf.b020f3c4d3817254f832c3153d5d4047.jpg\n",
            "      image_740_jpg.rf.bb45115dd9add31efda4687b92a2f78f.jpg\n",
            "  test/\n",
            "    images/\n",
            "      youtube-596_jpg.rf.11a8a4ac01d8aadb80eeb0406dfa579a.jpg\n",
            "      construction-675-_jpg.rf.bb4a05441be707256175e04929da3478.jpg\n",
            "      ppe_1073_jpg.rf.72ea8a293a4f3e1135219e33701b1099.jpg\n",
            "      youtube-631_jpg.rf.7c6ecf859c1b0a659f8ea057ad27aebd.jpg\n",
            "      construction-651-_jpg.rf.8fa283ce7693dbdf29eb98384f24cb85.jpg\n",
            "    labels/\n",
            "      2009_000496_jpg.rf.9a2d210fe0f5ea4b572aeb07e41ecbae.txt\n",
            "      youtube-114_jpg.rf.5e02b6574ace1f4b3689befbc5051cd0.txt\n",
            "      003357_jpg.rf.9867f91e88089bb68dc95947d5116d14.txt\n",
            "      construction-597-_jpg.rf.e18e918aae0aeecfdf8348513636d344.txt\n",
            "      construction-2-_mp4-162_jpg.rf.efad5f15524c736fe03b9c9936adc481.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    level = root.replace(dataset_path, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for f in files[:5]:\n",
        "        print(f\"{subindent}{f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYIuLY-uIPXo",
        "outputId": "bcb67ab4-92ad-4fc9-a7b3-6eb7200482be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total image files found: 2814\n",
            "Total label files found: 2801\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "image_files = glob.glob(os.path.join(dataset_path, \"**\", \"images\", \"*.jpg\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(dataset_path, \"**\", \"images\", \"*.jpeg\"), recursive=True) + \\\n",
        "              glob.glob(os.path.join(dataset_path, \"**\", \"images\", \"*.png\"), recursive=True)\n",
        "print(\"Total image files found:\", len(image_files))\n",
        "label_files = glob.glob(os.path.join(dataset_path, \"**\", \"labels\", \"*.txt\"), recursive=True)\n",
        "print(\"Total label files found:\", len(label_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiK6LePGIPa0",
        "outputId": "53bc9049-d95a-4bb9-b710-4b6b3959bc97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YAML saved inside dataset at: /content/drive/MyDrive/Infosys/css-data/css-data.yaml\n"
          ]
        }
      ],
      "source": [
        "yaml_content = \"\"\"train: /content/drive/MyDrive/Infosys/css-data/train/images\n",
        "val: /content/drive/MyDrive/Infosys/css-data/valid/images\n",
        "test: /content/drive/MyDrive/Infosys/css-data/test/images\n",
        "nc: 3\n",
        "names: [\"person\", \"helmet\", \"vest\"]\n",
        "\"\"\"\n",
        "yaml_path = \"/content/drive/MyDrive/Infosys/css-data/css-data.yaml\"\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "print(\"YAML saved inside dataset at:\", yaml_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3RtmPlyIPeT",
        "outputId": "dcfbce33-4bac-4a7c-8f89-eb9367142cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "css-data.yaml  README.dataset.txt  README.roboflow.txt\ttest  train  valid\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/MyDrive/Infosys/css-data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bavLWxUjItyN",
        "outputId": "639f58f8-29ac-43fb-ae6f-ec96e3c292fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage 1/3: Copying source data from Google Drive to local disk...\n",
            "Source data copied locally. Starting split (This will be fast)...\n",
            "Stage 2/3: Performing file copy on local disk...\n",
            "Local splitting complete.\n",
            "Stage 3/3: Copying final split result back to Google Drive...\n",
            "Final split successfully saved to Google Drive.\n",
            "\n",
            "ðŸŽ‰ Stratified dataset split completed! (Execution time drastically reduced) ðŸŽ‰\n",
            "Final split is located on Google Drive at: /content/drive/MyDrive/Infosys/css-data/traintestsplit_FAST\n",
            "----------------------------------------\n",
            "File Counts:\n",
            "Train Images: 1819\n",
            "Test Images:  520\n",
            "Val Images:   260\n",
            "----------------------------------------\n",
            "Total Labeled Images Split: 2599\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset_path = \"/content/drive/MyDrive/Infosys/css-data\"\n",
        "source_folder_name = \"train\"\n",
        "local_source_base = \"/tmp/css-data-local-source\"\n",
        "local_output_base = \"/tmp/traintestsplit\"\n",
        "local_original_images_path = os.path.join(local_source_base, source_folder_name, \"images\")\n",
        "local_original_labels_path = os.path.join(local_source_base, source_folder_name, \"labels\")\n",
        "drive_target_path = os.path.join(dataset_path, \"traintestsplit_FAST\")\n",
        "train_ratio = 0.7\n",
        "test_ratio = 0.2\n",
        "val_ratio = 0.1\n",
        "print(\"Stage 1/3: Copying source data from Google Drive to local disk...\")\n",
        "drive_source_path = os.path.join(dataset_path, source_folder_name)\n",
        "if os.path.exists(local_source_base):\n",
        "    shutil.rmtree(local_source_base)\n",
        "shutil.copytree(drive_source_path, os.path.join(local_source_base, source_folder_name))\n",
        "print(\"Source data copied locally. Starting split (This will be fast)...\")\n",
        "for split in [\"train\", \"test\", \"val\"]:\n",
        "    for sub in [\"images\", \"labels\"]:\n",
        "        split_path = os.path.join(local_output_base, split, sub)\n",
        "        os.makedirs(split_path, exist_ok=True)\n",
        "image_files = [f for f in os.listdir(local_original_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "labels = []\n",
        "for img in image_files:\n",
        "    label_file = os.path.join(local_original_labels_path, img.rsplit('.', 1)[0] + \".txt\")\n",
        "    class_id = -1\n",
        "    if os.path.exists(label_file):\n",
        "        with open(label_file, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            if lines:\n",
        "                try:\n",
        "                    class_id = int(lines[0].split()[0])\n",
        "                except (ValueError, IndexError):\n",
        "                    pass\n",
        "    labels.append(class_id)\n",
        "labeled_image_files = [img for img, label in zip(image_files, labels) if label != -1]\n",
        "labeled_labels = [label for label in labels if label != -1]\n",
        "if labeled_image_files:\n",
        "    train_imgs, temp_imgs, train_labels, temp_labels = train_test_split(\n",
        "        labeled_image_files, labeled_labels, stratify=labeled_labels, test_size=(1-train_ratio), random_state=42\n",
        "    )\n",
        "    test_size = test_ratio / (test_ratio + val_ratio)\n",
        "    val_imgs, test_imgs, val_labels, test_labels = train_test_split(\n",
        "        temp_imgs, temp_labels, stratify=temp_labels, test_size=test_size, random_state=42\n",
        "    )\n",
        "else:\n",
        "    train_imgs, test_imgs, val_imgs = [], [], []\n",
        "    print(\"No labeled images found to perform the split.\")\n",
        "print(\"Stage 2/3: Performing file copy on local disk...\")\n",
        "def copy_files(img_list, split_name):\n",
        "    for img in img_list:\n",
        "        img_src = os.path.join(local_original_images_path, img)\n",
        "        label_src = os.path.join(local_original_labels_path, img.rsplit('.', 1)[0] + \".txt\")\n",
        "        img_dst = os.path.join(local_output_base, split_name, \"images\", img)\n",
        "        label_dst = os.path.join(local_output_base, split_name, \"labels\", img.rsplit('.', 1)[0] + \".txt\")\n",
        "        shutil.copy2(img_src, img_dst)\n",
        "        if os.path.exists(label_src):\n",
        "            shutil.copy2(label_src, label_dst)\n",
        "if train_imgs: copy_files(train_imgs, \"train\")\n",
        "if test_imgs: copy_files(test_imgs, \"test\")\n",
        "if val_imgs: copy_files(val_imgs, \"val\")\n",
        "print(\"Local splitting complete.\")\n",
        "print(\"Stage 3/3: Copying final split result back to Google Drive...\")\n",
        "if os.path.exists(drive_target_path):\n",
        "    shutil.rmtree(drive_target_path)\n",
        "if os.path.exists(local_output_base):\n",
        "    shutil.copytree(local_output_base, drive_target_path)\n",
        "print(\"Final split successfully saved to Google Drive.\")\n",
        "def count_images_in_dir(directory):\n",
        "    if os.path.exists(directory):\n",
        "        return len([f for f in os.listdir(directory) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "    return 0\n",
        "final_train_count = count_images_in_dir(os.path.join(local_output_base, \"train\", \"images\"))\n",
        "final_test_count = count_images_in_dir(os.path.join(local_output_base, \"test\", \"images\"))\n",
        "final_val_count = count_images_in_dir(os.path.join(local_output_base, \"val\", \"images\"))\n",
        "print(\"\\nStratified dataset split completed! (Execution time drastically reduced)\")\n",
        "print(f\"Final split is located on Google Drive at: {drive_target_path}\")\n",
        "print(\"-\" * 40)\n",
        "print(\"File Counts:\")\n",
        "print(f\"Train Images: {final_train_count}\")\n",
        "print(f\"Test Images:  {final_test_count}\")\n",
        "print(f\"Val Images:   {final_val_count}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Total Labeled Images Split: {final_train_count + final_test_count + final_val_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD1yi9IoIt1S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVe8CnNHIt4R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cbmI9Y5It8z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU8kSaZgIuAO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
